{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88015722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore the TensorFlow binary optimization warning (AVX2 FMA)\n",
    "import os; os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "\n",
    "import transformers\n",
    "\n",
    "#Set to avoid warning messages.\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ac3d23",
   "metadata": {},
   "source": [
    "## 03.02. Content Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e4567c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing is a growing domain in machine learning. At Caltech's Computer Science & Artificial Intelligence Lab, we design, benchmark, and train applications to detect, extract, and interpret binary numbers and other information by searching neural networks. Our algorithms are designed to identify natural languages by the complexity of their \n",
      "-----------------\n",
      "Natural Language Processing is a growing domain in machine learning, as well as as in non-interactive programming using machine learning techniques in general.\n",
      "\n",
      "Machine Learning In Machine Learning\n",
      "\n",
      "In addition to machine learning, machine learning also incorporates the use of many other processes, including reinforcement learning for examples, \n",
      "-----------------\n",
      "Natural Language Processing is a growing domain in machine learning, providing solutions for many human-related problems including visual memory and complex language processing. Its main challenge has been overcoming the computational complexities of deep learning and computational modeling. The paper's conclusion is that human-driven problems of computational design are the bottleneck for \n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "text_generator = pipeline(\"text-generation\", \n",
    "                          model=\"gpt2\")\n",
    "transformers.set_seed(1)\n",
    "\n",
    "input_text=\"Natural Language Processing is a \\\n",
    "growing domain in machine learning\"\n",
    "\n",
    "synthetic_text=text_generator(input_text,\n",
    "                              num_return_sequences=3,\n",
    "                              max_new_tokens=50)\n",
    "\n",
    "for text in synthetic_text:\n",
    "    print(text.get(\"generated_text\") ,\"\\n-----------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863bfa0e",
   "metadata": {},
   "source": [
    "## 03.04. Chatbot Conversation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10b9b6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlenderbotSmallConfig {\n",
      "  \"_name_or_path\": \"facebook/blenderbot_small-90M\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BlenderbotSmallForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 8,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"do_blenderbot_90_layernorm\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 16,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 8,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layernorm_variant\": \"xlm\",\n",
      "  \"length_penalty\": 0.65,\n",
      "  \"max_length\": 128,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 20,\n",
      "  \"model_type\": \"blenderbot-small\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 10,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.39.1\",\n",
      "  \"unk_token_id\": 3,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 54944\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import  Conversation\n",
    "\n",
    "conversational_pipeline = pipeline(\"conversational\", \n",
    "                                   model=\"facebook/blenderbot_small-90M\")\n",
    "\n",
    "print(conversational_pipeline.model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "943e7009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First Exchange: \n",
      "--------------------\n",
      " User Input: Do you have any hobbies?\n",
      " Bot Output: yes, i love going to the beach. what about you? do you have any hobbies?\n",
      "\n",
      "Second Exchange: \n",
      "--------------------\n",
      " User Input: I like to watch movies\n",
      " Bot Output: i love going to the beach. i also like to watch movies. what kind of movies do you like?\n",
      "\n",
      "Third Exchange: \n",
      "--------------------\n",
      " User Input: action movies\n",
      " Bot Output: i love going to the beach as well. i like action movies as well, but i don't get to see them often.\n",
      "\n",
      "Accessing All Responses: \n",
      "Conversation id: 49cd11cf-ea12-46a3-b054-4ad5317014ff\n",
      "user: Do you have any hobbies?\n",
      "assistant: yes, i love going to the beach. what about you? do you have any hobbies?\n",
      "user: I like to watch movies\n",
      "assistant: i love going to the beach. i also like to watch movies. what kind of movies do you like?\n",
      "user: action movies\n",
      "assistant: i love going to the beach as well. i like action movies as well, but i don't get to see them often.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Sample inputs\n",
    "first_input=\"Do you have any hobbies?\"\n",
    "second_input = \"I like to watch movies\"\n",
    "third_input = \"action movies\"\n",
    "\n",
    "#Create a context\n",
    "bot_conversation = Conversation(first_input)\n",
    "\n",
    "print(\"\\nFirst Exchange: \\n--------------------\")\n",
    "\n",
    "conversational_pipeline(bot_conversation)\n",
    "print(\" User Input:\", bot_conversation.past_user_inputs[0])\n",
    "print(\" Bot Output:\", bot_conversation.generated_responses[0])\n",
    "\n",
    "print(\"\\nSecond Exchange: \\n--------------------\")\n",
    "bot_conversation.add_user_input(second_input)\n",
    "conversational_pipeline(bot_conversation)\n",
    "\n",
    "print(\" User Input:\", bot_conversation.past_user_inputs[1])\n",
    "print(\" Bot Output:\", bot_conversation.generated_responses[1])\n",
    "\n",
    "print(\"\\nThird Exchange: \\n--------------------\")\n",
    "bot_conversation.add_user_input(third_input)\n",
    "conversational_pipeline(bot_conversation)\n",
    "\n",
    "print(\" User Input:\", bot_conversation.past_user_inputs[2])\n",
    "print(\" Bot Output:\", bot_conversation.generated_responses[2])\n",
    "\n",
    "print(\"\\nAccessing All Responses: \")\n",
    "print(bot_conversation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf9be7f",
   "metadata": {},
   "source": [
    "## 03.06. Translating with Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0ea71b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c818bc1c474438584ac0113fc726e14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a184d81f0c450ea93ee4ae53f019df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a480fd39a76c4e5da9c2a74a1602fecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2517bbd125a44e22ab4a002cd35b3db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed54be111a94cfe913093a08376a5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German Translation:  Acme ist ein Technologieunternehmen mit Sitz in New York und Paris.\n",
      "French Translation:  Acme est une société technologique basée à New York et à Paris.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "source_english=\"Acme is a technology company based in New York and Paris\"\n",
    "\n",
    "inputs_german = tokenizer(\n",
    "    \"translate English to German: \" + source_english,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "outputs_german = model.generate(\n",
    "    inputs_german[\"input_ids\"], \n",
    "    max_length=40)\n",
    "\n",
    "print(\"German Translation: \",\n",
    "      tokenizer.decode(outputs_german[0], \n",
    "                       skip_special_tokens=True))\n",
    "\n",
    "inputs_french = tokenizer(\n",
    "    \"translate English to French: \" + source_english, \n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "outputs_french = model.generate(\n",
    "    inputs_french[\"input_ids\"], \n",
    "    max_length=40)\n",
    "\n",
    "print(\"French Translation: \", \n",
    "      tokenizer.decode(outputs_french[0], \n",
    "                       skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b4eacb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
